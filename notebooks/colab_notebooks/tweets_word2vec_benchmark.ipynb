{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweets_word2vec_benchmark.ipynb ",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8YxwpjDU0-DP",
        "outputId": "4979fac0-1dde-42d3-c9a2-ed78cf690ad6"
      },
      "source": [
        "# import libraries\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils\n",
        "import pandas as pd\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import numpy as np\n",
        "import xgboost \n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn import decomposition, ensemble\n",
        "from collections import Counter\n",
        "from nltk import ngrams"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Lu7aGp4A19"
      },
      "source": [
        "def classification_report(x_train, x_test, y_train, y_test):\n",
        "  models = []\n",
        "  models.append(('LogisticRegression', linear_model.LogisticRegression(solver='newton-cg',multi_class='multinomial')))\n",
        "  models.append(('RandomForest', ensemble.RandomForestClassifier(n_estimators=100)))\n",
        "\n",
        "  for name, model in models:\n",
        "      clf=model\n",
        "      clf.fit(x_train, y_train)\n",
        "      y_pred=clf.predict(x_test)\n",
        "      print(f\"{name}:\")\n",
        "      print(f\"accuracy: {metrics.accuracy_score(y_pred=y_pred, y_true=y_test)}\")\n",
        "      print(f\"precision: {metrics.precision_score(y_pred=y_pred, y_true=y_test, average='macro')}\")\n",
        "      print(f\"recall: {metrics.recall_score(y_pred=y_pred, y_true=y_test, average='macro')}\")\n",
        "      print(f\"{metrics.classification_report(y_pred=y_pred, y_true=y_test)}\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXg0RuZAZlwf"
      },
      "source": [
        "def get_word_counts(data):\n",
        "  words = data.tweet.to_string().split()\n",
        "  return Counter(words)\n",
        "  "
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-O9ZWt4ILoE"
      },
      "source": [
        "# word2vec hyper parameters\n",
        "# min_count = corpusta kelimenin en az bulunma sayısı eğer kelime bu kadardan az geçiyorsa anlam ifade etmediği varsayılır(default=5)\n",
        "# vector_size = kelimelerin ifade edileceği vektörün boyut sayısı\n",
        "# window = current ve predicted word arasındaki maksimum mesafe\n",
        "# sg = 0 cbow, 1 skip-gram\n",
        "# negative = eğer sıfırdan büyük olursa negative sampling kullanılır 5-20 arasında olmalı\n",
        "# alpha = başlangıç learning rate\n",
        "# min_alpha = eğitim aşamasında learning rate linear olarak bunu düşer\n",
        "# epoch = iterasyon sayısı\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCziQoyb0qbe"
      },
      "source": [
        "def labelize_tweets_ug(tweets,label):\n",
        "    result = []\n",
        "    prefix = label\n",
        "    for i, t in zip(tweets.index, tweets):\n",
        "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
        "    return result"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPao5rpSYA_2"
      },
      "source": [
        "def train_word2vec(corpus, n_epoch, name_corpus, sg, vector_size, negative, window, min_count, alpha, min_alpha):\n",
        "  cores = multiprocessing.cpu_count()\n",
        "  model = Word2Vec(sg=sg, size=vector_size, negative=negative, window=window, min_count=min_count, workers=cores, alpha=alpha, min_alpha=min_alpha)\n",
        "  model.build_vocab([x.words for x in tqdm(corpus)])\n",
        "\n",
        "  for epoch in range(n_epoch):\n",
        "    model.train(utils.shuffle([x.words for x in tqdm(corpus)]), total_examples=len(corpus), epochs=1)\n",
        "    model.alpha -= 0.002\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "  model.save(f\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/trained_embeddings/{name_corpus}_sg_{sg}_size_{vector_size}_window_{window}_min_count_{min_count}.model\")\n",
        "  return model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL63uMQfkxrK"
      },
      "source": [
        "def get_mean_vector(model, words):\n",
        "    # remove out-of-vocabulary words\n",
        "    words = [word for word in words if word in model.wv]\n",
        "    if len(words) >= 1:\n",
        "        return np.mean(model[words], axis=0)\n",
        "    else:\n",
        "        return np.zeros((1, model.vector_size))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVMy-vj1lQQm"
      },
      "source": [
        "def get_vectors(model, corpus):\n",
        "  vectors = []\n",
        "  for sentence in corpus:\n",
        "      vec = get_mean_vector(model, sentence)\n",
        "      vectors.append(vec)\n",
        "  return vectors"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULEuRdQeqyzs"
      },
      "source": [
        "def get_max_len_sentence(series):\n",
        "  res = series.str.split().str.len().max()\n",
        "\n",
        "  print(f\"The maximum length in words are : {res}\") "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nqZ3LW8lur1"
      },
      "source": [
        "**TWEET METINLERI İÇİN WORD2VEC BENCHMARK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWfrOSNVl3U-"
      },
      "source": [
        "tweet_train = pd.read_csv(\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/preprocess_train.csv\")\n",
        "tweet_test = pd.read_csv(\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/preprocess_test.csv\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7vZvjFmJHN"
      },
      "source": [
        "tweet_test.dropna(inplace=True)\n",
        "tweet_test.reset_index(drop=True,inplace=True)\n",
        "\n",
        "tweet_train.dropna(inplace=True)\n",
        "tweet_train.reset_index(drop=True,inplace=True)\n",
        "\n",
        "x_train=tweet_train.tweet\n",
        "y_train=tweet_train.sentiment.map({'olumlu':1,'olumsuz':-1,'notr':0}).values\n",
        "x_test=tweet_test.tweet\n",
        "y_test=tweet_test.sentiment.map({'olumlu':1,'olumsuz':-1,'notr':0}).values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKY4-aLTmMBM"
      },
      "source": [
        "concat = pd.concat([x_train, x_test])\n",
        "corpus = labelize_tweets_ug(concat, 'all')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnxp9_tbv5Gq"
      },
      "source": [
        "corpus_train = pd.DataFrame(x_train)['tweet'].apply(lambda x: x.split())\n",
        "corpus_test = pd.DataFrame(x_test)['tweet'].apply(lambda x: x.split())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOvAfCWonIDg"
      },
      "source": [
        "# min_count = corpusta kelimenin en az bulunma sayısı eğer kelime bu kadardan az geçiyorsa anlam ifade etmediği varsayılır(default=5)\n",
        "# vector_size = kelimelerin ifade edileceği vektörün boyut sayısı\n",
        "# window = current ve predicted word arasındaki maksimum mesafe\n",
        "# sg = 0 cbow, 1 skip-gram\n",
        "# negative = eğer sıfırdan büyük olursa negative sampling kullanılır 5-20 arasında olmalı\n",
        "# alpha = başlangıç learning rate\n",
        "# min_alpha = eğitim aşamasında learning rate linear olarak bunu düşer\n",
        "# epoch = iterasyon sayısı"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VTyWTQ5prG6r",
        "outputId": "05558079-171e-4849-acef-daf5d73370f4"
      },
      "source": [
        "get_max_len_sentence(pd.DataFrame(concat).tweet)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximum length in words are : 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LoeKUIrq3-C"
      },
      "source": [
        "# sg=0 epoch=25 negative=5 için (sg karar vermek için ilk deneme ikisi için yapılacak)\n",
        "# alpha 0.5 0.01 0.05 0.1 her biri window = 3, vector_size = 150 kullanılacak \n",
        "# window 3 5 7 her biri alpha = 0.05, vector_size = 150 kullanılacak \n",
        "# vector_size 25 50 150 200 her biri  için window = 3, alpha = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN7wkxjFmj_M"
      },
      "source": [
        "model_1 = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.5,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zs2aoYW2wKhe",
        "outputId": "883e8c8e-8cf7-4935-b4f0-37086e544a7e"
      },
      "source": [
        "vectors_train = get_vectors(model=model_1,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model_1,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PxDKsaIRwxY5",
        "outputId": "fc3899bc-64a4-44d5-ac58-6d8a6a3048f5"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.5481438515081206\n",
            "precision: 0.5475194240183531\n",
            "recall: 0.5290639683382075\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.56      0.70      0.62      1373\n",
            "           0       0.52      0.48      0.50      1160\n",
            "           1       0.56      0.41      0.47       915\n",
            "\n",
            "    accuracy                           0.55      3448\n",
            "   macro avg       0.55      0.53      0.53      3448\n",
            "weighted avg       0.55      0.55      0.54      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.5580046403712297\n",
            "precision: 0.5753731214120604\n",
            "recall: 0.5341337792989448\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.54      0.76      0.63      1373\n",
            "           0       0.56      0.45      0.50      1160\n",
            "           1       0.63      0.39      0.48       915\n",
            "\n",
            "    accuracy                           0.56      3448\n",
            "   macro avg       0.58      0.53      0.54      3448\n",
            "weighted avg       0.57      0.56      0.55      3448\n",
            "\n",
            "SVM:\n",
            "accuracy: 0.5551044083526682\n",
            "precision: 0.5797883291226311\n",
            "recall: 0.5253056698420776\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.53      0.79      0.64      1373\n",
            "           0       0.55      0.44      0.49      1160\n",
            "           1       0.66      0.34      0.45       915\n",
            "\n",
            "    accuracy                           0.56      3448\n",
            "   macro avg       0.58      0.53      0.53      3448\n",
            "weighted avg       0.57      0.56      0.54      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "XpeTWvLo3oYl",
        "outputId": "1c4d56cb-3a58-4b3a-f619-7d041238721b"
      },
      "source": [
        "# deneme 2\n",
        "model_2 = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=1, \n",
        "                         negative=5,\n",
        "                         alpha = 0.5,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17222/17222 [00:00<00:00, 1182153.43it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1588265.25it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1536573.14it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1686338.36it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1906119.47it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1524863.39it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1882229.03it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2095570.16it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1987735.37it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1889911.40it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1761812.28it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1874998.14it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1647229.40it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2091020.51it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1745169.32it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1630755.24it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1974046.33it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2083782.01it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1960065.76it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1932742.11it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1494420.38it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1717655.95it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1681353.37it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1611545.49it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1752749.28it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1974370.07it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8rvBQAvG4CK_",
        "outputId": "3fce98ce-6171-402f-e456-87eaf2b5d8cf"
      },
      "source": [
        "vectors_train = get_vectors(model=model_2,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model_2,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "h-CEpQeS4jtW",
        "outputId": "a8112dd4-eb95-4c17-cc04-a81bccc241d0"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.5417633410672854\n",
            "precision: 0.5452278884679288\n",
            "recall: 0.5214176098821507\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.54      0.70      0.61      1373\n",
            "           0       0.52      0.47      0.49      1160\n",
            "           1       0.57      0.39      0.47       915\n",
            "\n",
            "    accuracy                           0.54      3448\n",
            "   macro avg       0.55      0.52      0.52      3448\n",
            "weighted avg       0.54      0.54      0.53      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.537122969837587\n",
            "precision: 0.5474788257797004\n",
            "recall: 0.5113636633957368\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.52      0.73      0.61      1373\n",
            "           0       0.54      0.46      0.49      1160\n",
            "           1       0.58      0.34      0.43       915\n",
            "\n",
            "    accuracy                           0.54      3448\n",
            "   macro avg       0.55      0.51      0.51      3448\n",
            "weighted avg       0.54      0.54      0.52      3448\n",
            "\n",
            "SVM:\n",
            "accuracy: 0.5246519721577726\n",
            "precision: 0.5562719574055827\n",
            "recall: 0.4911408171437148\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.50      0.78      0.61      1373\n",
            "           0       0.53      0.42      0.47      1160\n",
            "           1       0.64      0.27      0.38       915\n",
            "\n",
            "    accuracy                           0.52      3448\n",
            "   macro avg       0.56      0.49      0.49      3448\n",
            "weighted avg       0.55      0.52      0.50      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3inQZRUrtBkv"
      },
      "source": [
        "# yukarıdaki sonuçlara göre sg=0 -> cbow yöntemi için daha başarılı oldu onunla diğer sonuçlar alınacak"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ8PHNLTtn2R"
      },
      "source": [
        "# alpha(learning rate) = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtO0gImktIbn"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.01,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "mfHkCqRetfmk",
        "outputId": "bb9b2add-bc6d-4d0d-9e86-4d662d06c61e"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "I47m7ABgtl-2",
        "outputId": "3fe97b71-17d9-4e3b-eb42-0fba554ea05b"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.44895591647331784\n",
            "precision: 0.4755311665469673\n",
            "recall: 0.4123676235443822\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.44      0.76      0.56      1373\n",
            "           0       0.44      0.28      0.34      1160\n",
            "           1       0.55      0.20      0.29       915\n",
            "\n",
            "    accuracy                           0.45      3448\n",
            "   macro avg       0.48      0.41      0.40      3448\n",
            "weighted avg       0.47      0.45      0.41      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.49564965197215777\n",
            "precision: 0.4971043298193725\n",
            "recall: 0.4751265317516162\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.50      0.66      0.57      1373\n",
            "           0       0.47      0.42      0.44      1160\n",
            "           1       0.52      0.35      0.42       915\n",
            "\n",
            "    accuracy                           0.50      3448\n",
            "   macro avg       0.50      0.48      0.48      3448\n",
            "weighted avg       0.50      0.50      0.49      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3NDXq-Vtund"
      },
      "source": [
        "# learning rate 0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbd1U86UtxYV"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Mk53FKIjt0B3",
        "outputId": "40a58efb-86d1-4e81-a0cc-8ec8d2d0d803"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fRRL4cFQt4Oo",
        "outputId": "07752af9-57b4-4d69-d101-c62fe47f3e4e"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6189095127610209\n",
            "precision: 0.6152101408702348\n",
            "recall: 0.6031816644939304\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.75      0.69      1373\n",
            "           0       0.60      0.56      0.58      1160\n",
            "           1       0.61      0.51      0.55       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.60      0.61      3448\n",
            "weighted avg       0.62      0.62      0.61      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6302204176334106\n",
            "precision: 0.6355996715037645\n",
            "recall: 0.6113736910573524\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.79      0.69      1373\n",
            "           0       0.63      0.54      0.58      1160\n",
            "           1       0.65      0.50      0.57       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.64      0.61      0.62      3448\n",
            "weighted avg       0.63      0.63      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz0iXMrlt5Fw"
      },
      "source": [
        "# learning rate 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y67dlPnSt8GK"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.1,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "zColPCbsuE5k",
        "outputId": "2ffe3ab0-02d3-4375-ec18-cf456a2c97d3"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "pV5tAPDnuJm7",
        "outputId": "87d330b5-4d46-4bdf-e8e8-3bd42638ff78"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6218097447795824\n",
            "precision: 0.618427849527626\n",
            "recall: 0.6064234412052627\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.75      0.69      1373\n",
            "           0       0.62      0.55      0.58      1160\n",
            "           1       0.61      0.52      0.56       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.61      0.61      3448\n",
            "weighted avg       0.62      0.62      0.62      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6218097447795824\n",
            "precision: 0.6326078442422531\n",
            "recall: 0.5969728561904776\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.82      0.70      1373\n",
            "           0       0.62      0.54      0.58      1160\n",
            "           1       0.67      0.44      0.53       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.63      0.60      0.60      3448\n",
            "weighted avg       0.63      0.62      0.61      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx4bPZ2_uVfy"
      },
      "source": [
        "# window = 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QqXWkzvUuUeK",
        "outputId": "24f90b19-dbe4-4335-9dfd-02064124be48"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17222/17222 [00:00<00:00, 1365616.85it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1422327.09it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1999288.78it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1556002.49it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1823868.29it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2105281.21it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1830848.67it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1613561.41it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1485477.28it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1727804.04it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1732528.33it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1864495.99it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2031164.51it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1755859.49it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1948118.98it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1207467.09it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1839942.52it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2011929.46it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1784312.02it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1756628.09it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1800994.90it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1686417.10it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2104054.75it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2056609.73it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1927635.99it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1775933.11it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "xPBRjqXzul1G",
        "outputId": "ffff9cc0-5e60-4e2d-95fa-8be8638ff193"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "CIYqGZ4_uoFm",
        "outputId": "9f75278a-5d2c-478a-ca7a-8c7ccea15473"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6189095127610209\n",
            "precision: 0.6168600466393709\n",
            "recall: 0.6027603059955581\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.75      0.69      1373\n",
            "           0       0.60      0.55      0.58      1160\n",
            "           1       0.62      0.50      0.56       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.60      0.61      3448\n",
            "weighted avg       0.62      0.62      0.61      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6342807424593968\n",
            "precision: 0.6372955795484575\n",
            "recall: 0.6156354392383405\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.79      0.70      1373\n",
            "           0       0.64      0.54      0.59      1160\n",
            "           1       0.65      0.51      0.57       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.64      0.62      0.62      3448\n",
            "weighted avg       0.64      0.63      0.63      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8XEx9KupRg"
      },
      "source": [
        "# window size = 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_LfAvpEutjk"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 5,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Ph8qFhMYuvMk",
        "outputId": "7e632dea-3863-4962-92d4-932614999c83"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6247099767981439\n",
            "precision: 0.6236967945700024\n",
            "recall: 0.6091632675775828\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.76      0.69      1373\n",
            "           0       0.61      0.55      0.58      1160\n",
            "           1       0.63      0.52      0.57       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.61      0.61      3448\n",
            "weighted avg       0.62      0.62      0.62      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6337006960556845\n",
            "precision: 0.6380770695875175\n",
            "recall: 0.6143761774325188\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.80      0.70      1373\n",
            "           0       0.63      0.54      0.59      1160\n",
            "           1       0.65      0.50      0.57       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.64      0.61      0.62      3448\n",
            "weighted avg       0.64      0.63      0.63      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q71fQ3vbu2eC"
      },
      "source": [
        "# window size = 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "40kIrtDbu1R2",
        "outputId": "c8876684-22ae-41fe-e6eb-85ce3a4e1cde"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 7,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17222/17222 [00:00<00:00, 1530939.18it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2073850.98it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1746181.82it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1828716.54it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1892188.70it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1857448.21it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1556438.34it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1564393.46it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1705972.88it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1931243.58it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1783915.43it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1864351.62it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1863678.20it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1784091.67it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1920512.16it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1473628.13it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1843087.96it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1793660.69it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2084022.49it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1843087.96it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1709768.59it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2010137.85it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1830245.61it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1953281.51it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1567822.88it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1824697.59it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6293503480278422\n",
            "precision: 0.6274789248025936\n",
            "recall: 0.6141981921571701\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.64      0.76      0.69      1373\n",
            "           0       0.61      0.56      0.58      1160\n",
            "           1       0.63      0.53      0.57       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.61      0.62      3448\n",
            "weighted avg       0.63      0.63      0.63      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6415313225058005\n",
            "precision: 0.6461515174632755\n",
            "recall: 0.6227136908643017\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.80      0.71      1373\n",
            "           0       0.64      0.55      0.59      1160\n",
            "           1       0.66      0.51      0.58       915\n",
            "\n",
            "    accuracy                           0.64      3448\n",
            "   macro avg       0.65      0.62      0.63      3448\n",
            "weighted avg       0.64      0.64      0.64      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMnCFd1vu-yL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMEjCkh9vC9D"
      },
      "source": [
        "# vector size = 25\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "d2bHOBPlvF_A",
        "outputId": "a89d7cb1-8607-427a-f5b5-b461d2e44868"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=25,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17222/17222 [00:00<00:00, 950764.11it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1579927.90it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1640383.86it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1583321.72it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1552991.71it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1930314.62it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2025753.08it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1960757.42it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1966094.27it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1621639.36it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1986915.24it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1433504.73it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2034597.17it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1671471.30it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2032021.59it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1917198.91it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1682293.15it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1932431.88it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1662699.19it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1455192.56it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1823269.81it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1643668.59it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1932638.68it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1797901.87it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1913339.43it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2004670.82it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.5948375870069605\n",
            "precision: 0.589717210193724\n",
            "recall: 0.5777202159350797\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.73      0.67      1373\n",
            "           0       0.58      0.54      0.56      1160\n",
            "           1       0.58      0.47      0.52       915\n",
            "\n",
            "    accuracy                           0.59      3448\n",
            "   macro avg       0.59      0.58      0.58      3448\n",
            "weighted avg       0.59      0.59      0.59      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6209396751740139\n",
            "precision: 0.6263826363497952\n",
            "recall: 0.6024506790698594\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.77      0.68      1373\n",
            "           0       0.62      0.56      0.58      1160\n",
            "           1       0.65      0.49      0.56       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.63      0.60      0.61      3448\n",
            "weighted avg       0.62      0.62      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LYFwoQ9vRIM"
      },
      "source": [
        "# vector  size = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "WwCctArMvT7J",
        "outputId": "ebaa9317-df11-440e-f0a5-0c8c582c2b2a"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=50,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17222/17222 [00:00<00:00, 1691075.82it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1567108.59it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1810701.21it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1748337.29it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1603959.22it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1980921.53it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1961183.30it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1819595.53it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1846905.05it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1986259.62it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1821247.13it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2092171.22it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1425133.24it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1892684.49it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2057312.62it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1886505.71it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2071709.74it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2059894.02it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1756072.92it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1744242.23it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1741634.80it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1535821.73it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1784488.34it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2068210.03it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1855110.78it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1739872.91it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6087587006960556\n",
            "precision: 0.6035299861321796\n",
            "recall: 0.5912452121003683\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.75      0.68      1373\n",
            "           0       0.60      0.55      0.57      1160\n",
            "           1       0.59      0.48      0.53       915\n",
            "\n",
            "    accuracy                           0.61      3448\n",
            "   macro avg       0.60      0.59      0.59      3448\n",
            "weighted avg       0.61      0.61      0.60      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6313805104408353\n",
            "precision: 0.6353577104008358\n",
            "recall: 0.6108383159420652\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.79      0.70      1373\n",
            "           0       0.64      0.56      0.59      1160\n",
            "           1       0.65      0.48      0.55       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.64      0.61      0.61      3448\n",
            "weighted avg       0.63      0.63      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0bBqXNivhF6"
      },
      "source": [
        "# vector size = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ElhiDOD8vmHo",
        "outputId": "cd8cf748-7fec-4269-8b40-56997d4bc89a"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=100,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17222/17222 [00:00<00:00, 1774537.01it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1269049.60it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1866857.14it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1873636.38it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1807032.16it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1773752.66it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1556103.05it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1915216.45it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2082940.79it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1839052.48it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2017999.82it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1617391.09it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2053160.81it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1774711.40it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2027458.84it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1452938.76it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2052752.38it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2022180.33it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1822671.73it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1445726.99it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1937615.44it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1515935.02it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1941156.17it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1911162.65it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1598811.50it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1881689.68it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6125290023201856\n",
            "precision: 0.6111973593631416\n",
            "recall: 0.5975730885925148\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.74      0.67      1373\n",
            "           0       0.60      0.55      0.57      1160\n",
            "           1       0.61      0.51      0.56       915\n",
            "\n",
            "    accuracy                           0.61      3448\n",
            "   macro avg       0.61      0.60      0.60      3448\n",
            "weighted avg       0.61      0.61      0.61      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6273201856148491\n",
            "precision: 0.6335717845541599\n",
            "recall: 0.6086259322191375\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.78      0.69      1373\n",
            "           0       0.64      0.54      0.59      1160\n",
            "           1       0.65      0.50      0.56       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.61      0.61      3448\n",
            "weighted avg       0.63      0.63      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6cZrG4FvuGZ"
      },
      "source": [
        "# vector size = 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "8visbtc0vrp4",
        "outputId": "2d00d809-cc16-443b-eb55-8b11bc35e68e"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17222/17222 [00:00<00:00, 1906421.31it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1980649.94it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1770405.22it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1672748.62it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1813155.54it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1780397.90it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1787800.80it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1773360.75it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1803783.24it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1711997.33it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1831498.57it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1579547.87it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1346951.28it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1863918.65it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1892734.08it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2032421.81it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1681470.79it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1764566.73it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1615546.24it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2005617.04it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1821982.13it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1802432.96it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1877727.61it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1846385.75it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1860078.89it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2017492.56it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6203596287703016\n",
            "precision: 0.6175282233111985\n",
            "recall: 0.6038569545378668\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.75      0.69      1373\n",
            "           0       0.60      0.56      0.58      1160\n",
            "           1       0.62      0.50      0.55       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.60      0.61      3448\n",
            "weighted avg       0.62      0.62      0.62      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6305104408352669\n",
            "precision: 0.6367282877365646\n",
            "recall: 0.6101258487544085\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.80      0.70      1373\n",
            "           0       0.63      0.54      0.58      1160\n",
            "           1       0.66      0.49      0.56       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.64      0.61      0.61      3448\n",
            "weighted avg       0.63      0.63      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4hzi59GvzCH"
      },
      "source": [
        "# vector size = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7SUBZoTqvyWD",
        "outputId": "e4a2ecf8-7ca4-4f95-9f1f-2d92a445b7d5"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=200,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17222/17222 [00:00<00:00, 1981301.87it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1807981.97it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1818084.20it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1760524.09it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1718800.35it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1996691.36it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1847471.89it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1971944.62it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2055205.38it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1824236.77it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1929798.92it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1885422.41it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1351866.89it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1741466.85it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2032307.44it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1452266.90it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1735817.36it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1602606.96it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1580757.69it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1625032.14it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2034482.57it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1810247.44it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1824697.59it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1450895.90it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1571233.19it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1721750.10it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6258700696055685\n",
            "precision: 0.6234586354462887\n",
            "recall: 0.6105557355685504\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.64      0.75      0.69      1373\n",
            "           0       0.62      0.56      0.59      1160\n",
            "           1       0.62      0.52      0.56       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.62      0.61      0.61      3448\n",
            "weighted avg       0.62      0.63      0.62      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6302204176334106\n",
            "precision: 0.6340341458802654\n",
            "recall: 0.6108753901558647\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.79      0.70      1373\n",
            "           0       0.64      0.54      0.58      1160\n",
            "           1       0.64      0.50      0.56       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.61      0.61      3448\n",
            "weighted avg       0.63      0.63      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWJnoUaRv25y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajvxKRPqv4Ne"
      },
      "source": [
        "# en iyiler sq=0, alpha=0.1, window_size=7, vector_size=200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "QT7j2KSUv5zU",
        "outputId": "bbd6b0c4-d8f0-427e-eaa3-f279309856da"
      },
      "source": [
        "model = train_word2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         sg=0, \n",
        "                         negative=5,\n",
        "                         alpha = 0.1,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 7,\n",
        "                         vector_size=200,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 17222/17222 [00:00<00:00, 1655459.13it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1604850.11it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1400188.09it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2069335.76it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1672438.78it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1719987.22it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2066139.51it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1672012.95it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1741214.98it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1941625.77it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1617608.41it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2029794.69it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1758295.69it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2036834.63it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1860126.79it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 2005282.98it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1949906.96it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1763748.10it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1798528.58it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1572361.85it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1577030.47it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1696556.91it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1651258.51it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1766465.41it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1460695.29it/s]\n",
            "100%|██████████| 17222/17222 [00:00<00:00, 1666612.14it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.62122969837587\n",
            "precision: 0.6158902966170939\n",
            "recall: 0.6060673402766655\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.64      0.76      0.69      1373\n",
            "           0       0.62      0.54      0.58      1160\n",
            "           1       0.59      0.52      0.55       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.61      0.61      3448\n",
            "weighted avg       0.62      0.62      0.62      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6290603248259861\n",
            "precision: 0.6409442046089743\n",
            "recall: 0.6040871207083883\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.83      0.70      1373\n",
            "           0       0.65      0.53      0.58      1160\n",
            "           1       0.67      0.45      0.54       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.64      0.60      0.61      3448\n",
            "weighted avg       0.64      0.63      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4BqMTVFxxkx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}