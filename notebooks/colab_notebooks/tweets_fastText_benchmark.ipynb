{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "tweets_fastText_benchmark.ipynb ",
   "provenance": [],
   "collapsed_sections": [],
   "machine_shape": "hm"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8YxwpjDU0-DP",
    "outputId": "3f309020-617e-43a4-e7da-64da14f8abb1"
   },
   "source": [
    "# import libraries\n",
    "from gensim.models.fasttext import FastText\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from sklearn import utils\n",
    "import pandas as pd\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import numpy as np\n",
    "import xgboost \n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn import decomposition, ensemble\n",
    "from collections import Counter\n",
    "from nltk import ngrams"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ],
     "name": "stderr"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "72Lu7aGp4A19"
   },
   "source": [
    "def classification_report(x_train, x_test, y_train, y_test):\n",
    "  models = []\n",
    "  models.append(('LogisticRegression', linear_model.LogisticRegression(solver='newton-cg',multi_class='multinomial')))\n",
    "  models.append(('RandomForest', ensemble.RandomForestClassifier(n_estimators=100)))\n",
    "\n",
    "  for name, model in models:\n",
    "      clf=model\n",
    "      clf.fit(x_train, y_train)\n",
    "      y_pred=clf.predict(x_test)\n",
    "      print(f\"{name}:\")\n",
    "      print(f\"accuracy: {metrics.accuracy_score(y_pred=y_pred, y_true=y_test)}\")\n",
    "      print(f\"precision: {metrics.precision_score(y_pred=y_pred, y_true=y_test, average='macro')}\")\n",
    "      print(f\"recall: {metrics.recall_score(y_pred=y_pred, y_true=y_test, average='macro')}\")\n",
    "      print(f\"{metrics.classification_report(y_pred=y_pred, y_true=y_test)}\")"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mXg0RuZAZlwf"
   },
   "source": [
    "def get_word_counts(data):\n",
    "  words = data.tweet.to_string().split()\n",
    "  return Counter(words)\n",
    "  "
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g-O9ZWt4ILoE"
   },
   "source": [
    "# fastText hyper parameters\n",
    "# sg = 0 cbow, 1 skip-gram\n",
    "# min_count = corpusta kelimenin en az bulunma sayısı eğer kelime bu kadardan az geçiyorsa anlam ifade etmediği varsayılır(default=5)\n",
    "# vector_size = kelimelerin ifade edileceği vektörün boyut sayısı\n",
    "# window = current ve predicted word arasındaki maksimum mesafe\n",
    "# loss = \"ns\" \"hs\" \"softmax\"\n",
    "# negative = eğer sıfırdan büyük olursa negative sampling kullanılır 5-20 arasında olmalı\n",
    "# alpha = başlangıç learning rate\n",
    "# min_n: char ngram minimum uzunluğu default:3\n",
    "# max_n: max length of char ngrams (Default 6)\n",
    "# epoch = iterasyon sayısı\n"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lCziQoyb0qbe"
   },
   "source": [
    "def labelize_tweets_ug(tweets,label):\n",
    "    result = []\n",
    "    prefix = label\n",
    "    for i, t in zip(tweets.index, tweets):\n",
    "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
    "    return result"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NPao5rpSYA_2"
   },
   "source": [
    "def train_fasText(corpus, n_epoch, name_corpus, sg, vector_size, negative, window, min_count, alpha, min_n, max_n):\n",
    "  cores = multiprocessing.cpu_count()\n",
    "  model = FastText(sg=sg, size=vector_size, negative=negative, window=window, min_count=min_count, workers=cores, alpha=alpha, min_n=min_n, max_n=max_n)\n",
    "  model.build_vocab([x.words for x in tqdm(corpus)])\n",
    "\n",
    "  for epoch in range(n_epoch):\n",
    "    model.train(utils.shuffle([x.words for x in tqdm(corpus)]), total_examples=len(corpus), epochs=1)\n",
    "    model.alpha -= 0.002\n",
    "    model.min_alpha = model.alpha\n",
    "\n",
    "  model.save(f\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/trained_embeddings/fastText_{name_corpus}_sg_{sg}_size_{vector_size}_window_{window}_min_count_{min_count}.model\")\n",
    "  return model"
   ],
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vL63uMQfkxrK"
   },
   "source": [
    "def get_mean_vector(word2vec_model, words):\n",
    "    # remove out-of-vocabulary words\n",
    "    words = [word for word in words if word in word2vec_model.wv]\n",
    "    if len(words) >= 1:\n",
    "        return np.mean(word2vec_model[words], axis=0)\n",
    "    else:\n",
    "        return np.zeros((1, word2vec_model.vector_size))"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oVMy-vj1lQQm"
   },
   "source": [
    "def get_vectors(model, corpus):\n",
    "  vectors = []\n",
    "  for sentence in corpus:\n",
    "      vec = get_mean_vector(model, sentence)\n",
    "      vectors.append(vec)\n",
    "  return vectors"
   ],
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ULEuRdQeqyzs"
   },
   "source": [
    "def get_max_len_sentence(series):\n",
    "  res = series.str.split().str.len().max()\n",
    "\n",
    "  print(f\"The maximum length in words are : {res}\") "
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nqZ3LW8lur1"
   },
   "source": [
    "**TWEET METINLERI İÇİN BENCHMARK**"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aWfrOSNVl3U-"
   },
   "source": [
    "tweet_train = pd.read_csv(\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/preprocess_train.csv\")\n",
    "tweet_test = pd.read_csv(\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/preprocess_test.csv\")"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jR7vZvjFmJHN"
   },
   "source": [
    "tweet_test.dropna(inplace=True)\n",
    "tweet_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "tweet_train.dropna(inplace=True)\n",
    "tweet_train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "x_train=tweet_train.tweet\n",
    "y_train=tweet_train.sentiment.map({'olumlu':1,'olumsuz':-1,'notr':0}).values\n",
    "x_test=tweet_test.tweet\n",
    "y_test=tweet_test.sentiment.map({'olumlu':1,'olumsuz':-1,'notr':0}).values"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fKY4-aLTmMBM"
   },
   "source": [
    "concat = pd.concat([x_train, x_test])\n",
    "corpus = labelize_tweets_ug(concat, 'all')"
   ],
   "execution_count": 13,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Hnxp9_tbv5Gq"
   },
   "source": [
    "corpus_train = pd.DataFrame(x_train)['tweet'].apply(lambda x: x.split())\n",
    "corpus_test = pd.DataFrame(x_test)['tweet'].apply(lambda x: x.split())"
   ],
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VTyWTQ5prG6r",
    "outputId": "12a7d4a5-17d1-4c30-aab0-ee47c6482278"
   },
   "source": [
    "get_max_len_sentence(pd.DataFrame(concat).tweet)"
   ],
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "The maximum length in words are : 27\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EkTaT6Vs4JxB"
   },
   "source": [
    "# n_epoch = 25, sg = 1, negative = 5, alpha = 0.065\n",
    "# değişenler:\n",
    "# min_n, max_n = (2,4)  (3,6) (4,8) window= 3 vector_size= 150\n",
    "# window 3 5 7 min,max = (4,8)\n",
    "# vector size = 25 50 75 100 window = 3 min,max = (4,8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JrwjUHNp5LHD"
   },
   "source": [
    "# min_n, max_n = (2,4)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oN7wkxjFmj_M",
    "outputId": "9e2e2fe7-8be5-4404-c6ec-c5daa93de667"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n =2,\n",
    "                        max_n = 4,\n",
    "                        window = 3,\n",
    "                        vector_size=150,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1330159.35it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1651334.01it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1819366.38it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1438643.77it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1762328.08it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1477033.09it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1388960.96it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1779739.90it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1633668.89it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1364997.51it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1789395.15it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1824144.64it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1564528.99it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1744789.94it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1942931.40it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1718105.36it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1517750.58it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 2044328.51it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1612013.02it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1460754.37it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1263875.97it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1510514.28it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1440997.12it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1303256.66it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1364095.32it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1362371.58it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.6487819025522041\n",
      "precision: 0.6430791713300478\n",
      "recall: 0.6346088512046438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.77      0.72      1373\n",
      "           0       0.64      0.59      0.61      1160\n",
      "           1       0.62      0.55      0.58       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.64      0.63      0.64      3448\n",
      "weighted avg       0.65      0.65      0.65      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6374709976798144\n",
      "precision: 0.6503638499540287\n",
      "recall: 0.6122830677581264\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.83      0.71      1373\n",
      "           0       0.65      0.56      0.60      1160\n",
      "           1       0.69      0.44      0.54       915\n",
      "\n",
      "    accuracy                           0.64      3448\n",
      "   macro avg       0.65      0.61      0.62      3448\n",
      "weighted avg       0.65      0.64      0.63      3448\n",
      "\n",
      "SVM:\n",
      "accuracy: 0.6850348027842227\n",
      "precision: 0.6851699325720052\n",
      "recall: 0.6700770517375645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.81      0.74      1373\n",
      "           0       0.69      0.62      0.65      1160\n",
      "           1       0.68      0.58      0.63       915\n",
      "\n",
      "    accuracy                           0.69      3448\n",
      "   macro avg       0.69      0.67      0.67      3448\n",
      "weighted avg       0.69      0.69      0.68      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FDicdHe05dwZ"
   },
   "source": [
    "# min_n, max_n = (3,6)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zzZ2FvS65o8R",
    "outputId": "0f43dd3d-dc4d-400f-a2a8-87f46f1c8072"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n =3,\n",
    "                        max_n = 6,\n",
    "                        window = 3,\n",
    "                        vector_size=150,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1427188.74it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1752451.62it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1649938.41it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1996194.76it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1608387.78it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1639192.67it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1412205.35it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1595174.87it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1690244.84it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 2026548.75it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1701592.51it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1327177.75it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1613921.92it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1795354.76it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1687954.00it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1900702.65it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1788996.30it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1946439.16it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1791347.67it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1503565.70it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1606241.88it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1607206.82it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1730453.09it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1667805.03it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1552791.41it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1769364.45it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.652262180974478\n",
      "precision: 0.6479713590702573\n",
      "recall: 0.6376235530740754\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.77      0.72      1373\n",
      "           0       0.65      0.59      0.62      1160\n",
      "           1       0.63      0.55      0.59       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.65      0.64      0.64      3448\n",
      "weighted avg       0.65      0.65      0.65      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6531322505800464\n",
      "precision: 0.6707176163641102\n",
      "recall: 0.628402999277249\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.84      0.72      1373\n",
      "           0       0.66      0.58      0.62      1160\n",
      "           1       0.72      0.47      0.57       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.67      0.63      0.63      3448\n",
      "weighted avg       0.66      0.65      0.64      3448\n",
      "\n",
      "SVM:\n",
      "accuracy: 0.6879350348027842\n",
      "precision: 0.6917683645173752\n",
      "recall: 0.6716663915006785\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.68      0.82      0.74      1373\n",
      "           0       0.69      0.63      0.66      1160\n",
      "           1       0.71      0.57      0.63       915\n",
      "\n",
      "    accuracy                           0.69      3448\n",
      "   macro avg       0.69      0.67      0.68      3448\n",
      "weighted avg       0.69      0.69      0.68      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHkYXcKz5jlO"
   },
   "source": [
    "# min_n, max_n = (4,8)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhbOfXN25tFy",
    "outputId": "bdfd4d50-a1d3-49bf-9508-a92bf7a4295e"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n =4,\n",
    "                        max_n = 8,\n",
    "                        window = 3,\n",
    "                        vector_size=150,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 33,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1634334.21it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1752451.62it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1595315.79it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1536377.05it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1249793.30it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1909444.98it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1700951.41it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1853397.23it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1650315.36it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1311491.04it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1961662.64it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1842053.95it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1646290.85it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 2042825.32it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1747322.29it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1411984.51it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1425864.66it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1585963.72it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1452266.90it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1445698.06it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1222859.38it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1732694.56it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1952859.05it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1528606.57it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1705610.34it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1780529.55it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.6368909512761021\n",
      "precision: 0.6336631485466095\n",
      "recall: 0.6213164743729886\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.77      0.70      1373\n",
      "           0       0.63      0.56      0.59      1160\n",
      "           1       0.62      0.53      0.58       915\n",
      "\n",
      "    accuracy                           0.64      3448\n",
      "   macro avg       0.63      0.62      0.62      3448\n",
      "weighted avg       0.64      0.64      0.63      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6490719257540604\n",
      "precision: 0.663095303564246\n",
      "recall: 0.6238536294439593\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.84      0.72      1373\n",
      "           0       0.65      0.57      0.61      1160\n",
      "           1       0.71      0.46      0.56       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.66      0.62      0.63      3448\n",
      "weighted avg       0.66      0.65      0.64      3448\n",
      "\n",
      "SVM:\n",
      "accuracy: 0.6830046403712297\n",
      "precision: 0.6868406076516459\n",
      "recall: 0.666676311200244\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.67      0.81      0.74      1373\n",
      "           0       0.69      0.62      0.66      1160\n",
      "           1       0.70      0.56      0.62       915\n",
      "\n",
      "    accuracy                           0.68      3448\n",
      "   macro avg       0.69      0.67      0.67      3448\n",
      "weighted avg       0.69      0.68      0.68      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FYB9R8uN5xUT"
   },
   "source": [
    ""
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yl9XXqTq61Uq"
   },
   "source": [
    "# window 3"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jaiCamEx63ns",
    "outputId": "383627fc-be4e-48da-acea-3b07989afa34"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n =4,\n",
    "                        max_n = 18,\n",
    "                        window = 3,\n",
    "                        vector_size=150,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1667959.07it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1938551.43it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1548862.57it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1422719.28it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1565173.09it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1576204.58it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1589383.55it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1158157.82it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1732819.26it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1374713.17it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1724298.28it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1668498.45it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1528347.83it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1580930.68it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1741928.80it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1188181.46it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 2096056.63it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1532953.53it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1258196.23it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1655269.45it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1319155.26it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1582627.92it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1663656.54it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1764997.89it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1541820.78it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1751814.12it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.6496519721577726\n",
      "precision: 0.645502872865643\n",
      "recall: 0.6342557066521046\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.77      0.71      1373\n",
      "           0       0.65      0.59      0.62      1160\n",
      "           1       0.62      0.54      0.58       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.65      0.63      0.64      3448\n",
      "weighted avg       0.65      0.65      0.65      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6548723897911833\n",
      "precision: 0.6724687404112669\n",
      "recall: 0.630759174955842\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.84      0.72      1373\n",
      "           0       0.67      0.59      0.62      1160\n",
      "           1       0.73      0.47      0.57       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.67      0.63      0.64      3448\n",
      "weighted avg       0.67      0.65      0.65      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jp75B4Ht68ir"
   },
   "source": [
    "# window 5"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JPP_8Vmi67yi",
    "outputId": "4bf45ede-eaf7-44df-b2cb-ce22dfc25af5"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n = 4,\n",
    "                        max_n = 8,\n",
    "                        window = 5,\n",
    "                        vector_size=150,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1276472.52it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1813519.71it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1911668.44it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1653753.60it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1287805.59it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1417943.65it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1867581.14it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1396857.66it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1488385.05it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1587078.78it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1715982.98it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1605349.44it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1911213.22it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1445032.88it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1768324.89it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1208881.62it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1685512.03it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1737194.96it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1439274.40it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1353031.70it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1718309.71it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1097518.89it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1511810.45it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1581726.89it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1715290.26it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1727266.94it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.6415313225058005\n",
      "precision: 0.6393875416255268\n",
      "recall: 0.6284215449616422\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.76      0.70      1373\n",
      "           0       0.63      0.57      0.60      1160\n",
      "           1       0.63      0.56      0.59       915\n",
      "\n",
      "    accuracy                           0.64      3448\n",
      "   macro avg       0.64      0.63      0.63      3448\n",
      "weighted avg       0.64      0.64      0.64      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6551624129930395\n",
      "precision: 0.6750695717340665\n",
      "recall: 0.6290173147797805\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.84      0.72      1373\n",
      "           0       0.67      0.59      0.63      1160\n",
      "           1       0.73      0.45      0.56       915\n",
      "\n",
      "    accuracy                           0.66      3448\n",
      "   macro avg       0.68      0.63      0.63      3448\n",
      "weighted avg       0.67      0.66      0.65      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wvucx8jR7DK5"
   },
   "source": [
    "# window 7"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lMTY4J0G7CcT",
    "outputId": "4120f511-21bb-49b1-da11-ba4d1f15d691"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n = 4,\n",
    "                        max_n = 8,\n",
    "                        window = 7,\n",
    "                        vector_size=150,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1697035.20it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1484652.93it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1526023.10it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 2071175.12it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 2000617.72it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1931760.05it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1378438.32it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1531523.45it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1951540.05it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1585580.78it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1548430.94it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1218116.42it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1492444.29it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1603282.80it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1354706.47it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1619857.45it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1362191.74it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1506042.23it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1505351.75it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1528121.50it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1597573.89it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1759837.83it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1684490.08it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1935279.40it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1712200.23it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1461581.96it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.6316705336426914\n",
      "precision: 0.6269684729508896\n",
      "recall: 0.6161324786764658\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.76      0.70      1373\n",
      "           0       0.62      0.56      0.59      1160\n",
      "           1       0.61      0.52      0.56       915\n",
      "\n",
      "    accuracy                           0.63      3448\n",
      "   macro avg       0.63      0.62      0.62      3448\n",
      "weighted avg       0.63      0.63      0.63      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6447215777262181\n",
      "precision: 0.6632324041858676\n",
      "recall: 0.6202809787839475\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.83      0.71      1373\n",
      "           0       0.64      0.58      0.61      1160\n",
      "           1       0.73      0.46      0.56       915\n",
      "\n",
      "    accuracy                           0.64      3448\n",
      "   macro avg       0.66      0.62      0.63      3448\n",
      "weighted avg       0.66      0.64      0.64      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AR_S6Ntf7LA2"
   },
   "source": [
    "# vector size 25"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9u15zqRE7J3q",
    "outputId": "ac982c22-cbc1-4a1b-e81c-c36be22f45d7"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n = 4,\n",
    "                        max_n = 8,\n",
    "                        window = 3,\n",
    "                        vector_size=25,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1645878.22it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1941677.96it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1621712.17it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1652769.79it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1712849.84it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1558688.55it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1390833.02it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1556136.57it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1901753.51it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1429137.06it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1625105.26it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1382871.70it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1829874.69it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1760481.18it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1060849.50it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1743610.69it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1428119.88it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1468863.56it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1471466.76it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 2038559.11it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1577788.29it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1570276.81it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1827143.81it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1630939.34it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1902354.52it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1595632.95it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.6197795823665894\n",
      "precision: 0.6142664843949519\n",
      "recall: 0.6020096003423312\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.77      0.70      1373\n",
      "           0       0.62      0.53      0.57      1160\n",
      "           1       0.59      0.50      0.54       915\n",
      "\n",
      "    accuracy                           0.62      3448\n",
      "   macro avg       0.61      0.60      0.60      3448\n",
      "weighted avg       0.62      0.62      0.61      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.660092807424594\n",
      "precision: 0.663147722575612\n",
      "recall: 0.6408168738097012\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.80      0.72      1373\n",
      "           0       0.67      0.61      0.64      1160\n",
      "           1       0.67      0.51      0.58       915\n",
      "\n",
      "    accuracy                           0.66      3448\n",
      "   macro avg       0.66      0.64      0.65      3448\n",
      "weighted avg       0.66      0.66      0.65      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HXfr9MHK7SHy"
   },
   "source": [
    "# vector size 50"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lV6Y95WM7R57",
    "outputId": "f8479834-58db-41fd-f7ff-c51359233de4"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n = 4,\n",
    "                        max_n = 8,\n",
    "                        window = 5,\n",
    "                        vector_size=50,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1411349.98it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1766724.64it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1597750.57it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1427019.57it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1718432.34it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1735316.95it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1959693.53it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1605278.09it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1750625.36it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1552991.71it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1395966.83it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1619603.22it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1430608.88it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1548895.78it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1629247.19it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1060538.00it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1467908.38it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1621420.95it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1527055.44it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1814704.27it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1713012.32it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1468773.96it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1196546.30it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1560068.75it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1639936.96it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1915876.81it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.6281902552204176\n",
      "precision: 0.623084895384813\n",
      "recall: 0.6124655910993159\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.76      0.70      1373\n",
      "           0       0.64      0.56      0.60      1160\n",
      "           1       0.59      0.52      0.55       915\n",
      "\n",
      "    accuracy                           0.63      3448\n",
      "   macro avg       0.62      0.61      0.61      3448\n",
      "weighted avg       0.63      0.63      0.62      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6592227378190255\n",
      "precision: 0.671673799363108\n",
      "recall: 0.6372324731273994\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.83      0.72      1373\n",
      "           0       0.67      0.59      0.63      1160\n",
      "           1       0.71      0.49      0.58       915\n",
      "\n",
      "    accuracy                           0.66      3448\n",
      "   macro avg       0.67      0.64      0.64      3448\n",
      "weighted avg       0.67      0.66      0.65      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jtQWP4xH7aB3"
   },
   "source": [
    "# vector size 75"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ok3oIPl97Z0v",
    "outputId": "4fc67641-2e30-4510-d8b7-eccab640cc9a"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n = 4,\n",
    "                        max_n = 8,\n",
    "                        window = 5,\n",
    "                        vector_size=75,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1556840.89it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1923939.37it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1877532.39it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1696915.61it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1493987.66it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1313494.26it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1475554.67it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1044376.54it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1671432.62it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1856541.16it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1478726.35it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1630387.17it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1501378.11it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1463892.34it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1706779.06it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1570925.66it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1628769.61it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1591379.43it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1669423.92it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1431459.39it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1468057.55it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1731780.67it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1350173.90it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1375812.88it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1499383.58it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1662546.11it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.627030162412993\n",
      "precision: 0.6228882545948219\n",
      "recall: 0.6128147179539472\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.64      0.76      0.69      1373\n",
      "           0       0.63      0.55      0.58      1160\n",
      "           1       0.60      0.54      0.57       915\n",
      "\n",
      "    accuracy                           0.63      3448\n",
      "   macro avg       0.62      0.61      0.61      3448\n",
      "weighted avg       0.63      0.63      0.62      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6534222737819025\n",
      "precision: 0.6697048766782502\n",
      "recall: 0.6291239295917255\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.63      0.84      0.72      1373\n",
      "           0       0.66      0.58      0.62      1160\n",
      "           1       0.72      0.47      0.57       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.67      0.63      0.63      3448\n",
      "weighted avg       0.66      0.65      0.64      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8n3QnWx7d4j"
   },
   "source": [
    "# vector size 100"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k-kf91r67Q0Q",
    "outputId": "57af3c6a-31c5-4e77-bbb0-b5fc3f623c03"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n = 4,\n",
    "                        max_n = 8,\n",
    "                        window = 5,\n",
    "                        vector_size=100,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1666958.29it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1713499.94it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1880220.30it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1617499.74it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1406266.86it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1566360.99it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1723352.11it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1801938.37it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1573834.97it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1827976.10it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1584850.22it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1562228.11it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1765256.68it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1482824.31it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1995753.54it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1737696.44it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1405199.95it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1580377.26it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1674842.99it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1621275.38it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1538667.91it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1577512.63it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1534810.12it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1498108.62it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1543072.36it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1799200.55it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.6415313225058005\n",
      "precision: 0.6377774169307019\n",
      "recall: 0.6267648249850534\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.65      0.77      0.71      1373\n",
      "           0       0.63      0.57      0.60      1160\n",
      "           1       0.62      0.54      0.58       915\n",
      "\n",
      "    accuracy                           0.64      3448\n",
      "   macro avg       0.64      0.63      0.63      3448\n",
      "weighted avg       0.64      0.64      0.64      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6528422273781903\n",
      "precision: 0.6713334355549536\n",
      "recall: 0.6291323927185452\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.84      0.71      1373\n",
      "           0       0.66      0.58      0.62      1160\n",
      "           1       0.73      0.48      0.58       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.67      0.63      0.64      3448\n",
      "weighted avg       0.66      0.65      0.64      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P4bCy1hCZQWf"
   },
   "source": [
    "# en iyiler vector_size = 100, window=5, min,max = (3,6)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j2h8CY1H7jQX",
    "outputId": "1d657ce9-a02e-490e-bf1a-d15c23016d57"
   },
   "source": [
    "model = train_fasText(corpus=corpus, \n",
    "                        n_epoch=25, \n",
    "                        name_corpus=\"tweet\", \n",
    "                        sg=1, \n",
    "                        negative=5,\n",
    "                        alpha = 0.065,\n",
    "                        min_n = 3,\n",
    "                        max_n = 6,\n",
    "                        window = 5,\n",
    "                        vector_size=100,\n",
    "                        min_count=2)\n",
    "\n",
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)\n",
    "\n",
    "\n",
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "100%|██████████| 17222/17222 [00:00<00:00, 1568061.12it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1864784.79it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1716268.38it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1482489.55it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1861996.79it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1755859.49it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1874560.22it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1623936.14it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1222590.31it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 2013836.56it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1575517.00it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1413282.92it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1410192.75it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1689493.71it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1926916.09it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1785414.59it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1959480.89it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 2076354.70it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1406403.76it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1542182.87it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1542051.18it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1655155.66it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1646103.27it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1685669.36it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1830152.87it/s]\n",
      "100%|██████████| 17222/17222 [00:00<00:00, 1866664.17it/s]\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.6453016241299304\n",
      "precision: 0.6400547229655147\n",
      "recall: 0.6289731910100733\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.66      0.78      0.72      1373\n",
      "           0       0.64      0.57      0.61      1160\n",
      "           1       0.62      0.53      0.57       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.64      0.63      0.63      3448\n",
      "weighted avg       0.64      0.65      0.64      3448\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.6499419953596288\n",
      "precision: 0.6663915291036622\n",
      "recall: 0.6245697460691407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.62      0.84      0.72      1373\n",
      "           0       0.66      0.57      0.61      1160\n",
      "           1       0.72      0.46      0.56       915\n",
      "\n",
      "    accuracy                           0.65      3448\n",
      "   macro avg       0.67      0.62      0.63      3448\n",
      "weighted avg       0.66      0.65      0.64      3448\n",
      "\n"
     ],
     "name": "stdout"
    }
   ]
  }
 ]
}