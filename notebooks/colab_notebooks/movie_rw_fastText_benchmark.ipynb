{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_rw_fastText_benchmark.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YxwpjDU0-DP",
        "outputId": "25e632a4-0e13-4ea9-930d-3c747ac9f24f"
      },
      "source": [
        "# import libraries\n",
        "from gensim.models.fasttext import FastText\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils\n",
        "import pandas as pd\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import numpy as np\n",
        "import xgboost \n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn import decomposition, ensemble\n",
        "from collections import Counter\n",
        "from nltk import ngrams"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Lu7aGp4A19"
      },
      "source": [
        "def classification_report(x_train, x_test, y_train, y_test):\n",
        "  models = []\n",
        "  models.append(('LogisticRegression', linear_model.LogisticRegression(solver='newton-cg',multi_class='multinomial')))\n",
        "  models.append(('RandomForest', ensemble.RandomForestClassifier(n_estimators=100)))\n",
        "\n",
        "  for name, model in models:\n",
        "      clf=model\n",
        "      clf.fit(x_train, y_train)\n",
        "      y_pred=clf.predict(x_test)\n",
        "      print(f\"{name}:\")\n",
        "      print(f\"accuracy: {metrics.accuracy_score(y_pred=y_pred, y_true=y_test)}\")\n",
        "      print(f\"precision: {metrics.precision_score(y_pred=y_pred, y_true=y_test, average='macro')}\")\n",
        "      print(f\"recall: {metrics.recall_score(y_pred=y_pred, y_true=y_test, average='macro')}\")\n",
        "      print(f\"{metrics.classification_report(y_pred=y_pred, y_true=y_test)}\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXg0RuZAZlwf"
      },
      "source": [
        "def get_word_counts(data):\n",
        "  words = data.tweet.to_string().split()\n",
        "  return Counter(words)\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-O9ZWt4ILoE"
      },
      "source": [
        "# fastText hyper parameters\n",
        "# sg = 0 cbow, 1 skip-gram\n",
        "# min_count = corpusta kelimenin en az bulunma sayısı eğer kelime bu kadardan az geçiyorsa anlam ifade etmediği varsayılır(default=5)\n",
        "# vector_size = kelimelerin ifade edileceği vektörün boyut sayısı\n",
        "# window = current ve predicted word arasındaki maksimum mesafe\n",
        "# loss = \"ns\" \"hs\" \"softmax\"\n",
        "# negative = eğer sıfırdan büyük olursa negative sampling kullanılır 5-20 arasında olmalı\n",
        "# alpha = başlangıç learning rate\n",
        "# min_n: char ngram minimum uzunluğu default:3\n",
        "# max_n: max length of char ngrams (Default 6)\n",
        "# epoch = iterasyon sayısı\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCziQoyb0qbe"
      },
      "source": [
        "def labelize_tweets_ug(tweets,label):\n",
        "    result = []\n",
        "    prefix = label\n",
        "    for i, t in zip(tweets.index, tweets):\n",
        "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
        "    return result"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPao5rpSYA_2"
      },
      "source": [
        "def train_fasText(corpus, n_epoch, name_corpus, sg, vector_size, negative, window, min_count, alpha, min_n, max_n):\n",
        "  cores = multiprocessing.cpu_count()\n",
        "  model = FastText(sg=sg, size=vector_size, negative=negative, window=window, min_count=min_count, workers=cores, alpha=alpha, min_n=min_n, max_n=max_n)\n",
        "  model.build_vocab([x.words for x in tqdm(corpus)])\n",
        "\n",
        "  for epoch in range(n_epoch):\n",
        "    model.train(utils.shuffle([x.words for x in tqdm(corpus)]), total_examples=len(corpus), epochs=1)\n",
        "    model.alpha -= 0.002\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "  model.save(f\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/trained_embeddings/fastText_{name_corpus}_sg_{sg}_size_{vector_size}_window_{window}_min_count_{min_count}.model\")\n",
        "  return model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL63uMQfkxrK"
      },
      "source": [
        "def get_mean_vector(word2vec_model, words):\n",
        "    # remove out-of-vocabulary words\n",
        "    words = [word for word in words if word in word2vec_model.wv]\n",
        "    if len(words) >= 1:\n",
        "        return np.mean(word2vec_model[words], axis=0)\n",
        "    else:\n",
        "        return np.zeros((1, word2vec_model.vector_size))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVMy-vj1lQQm"
      },
      "source": [
        "def get_vectors(model, corpus):\n",
        "  vectors = []\n",
        "  for sentence in corpus:\n",
        "      vec = get_mean_vector(model, sentence)\n",
        "      vectors.append(vec)\n",
        "  return vectors"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULEuRdQeqyzs"
      },
      "source": [
        "def get_max_len_sentence(series):\n",
        "  res = series.str.split().str.len().max()\n",
        "\n",
        "  print(f\"The maximum length in words are : {res}\") "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWfrOSNVl3U-"
      },
      "source": [
        "data = pd.read_csv(\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/preprocess_movie_sentiment.csv\")"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7vZvjFmJHN"
      },
      "source": [
        "data.dropna(inplace=True)\n",
        "data.reset_index(drop=True,inplace=True)\n",
        "\n",
        "x=data.comment\n",
        "y=data.sentiment.values\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKY4-aLTmMBM"
      },
      "source": [
        "corpus = labelize_tweets_ug(x, 'all')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnxp9_tbv5Gq"
      },
      "source": [
        "corpus_train = pd.DataFrame(x_train)['comment'].apply(lambda x: x.split())\n",
        "corpus_test = pd.DataFrame(x_test)['comment'].apply(lambda x: x.split())"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkTaT6Vs4JxB"
      },
      "source": [
        "# n_epoch = 25, sg = 1, negative = 5, alpha = 0.065\n",
        "# değişenler:\n",
        "# min_n, max_n = (2,4)  (3,6) (4,8) (8,26) window= 3 vector_size= 150\n",
        "# window 3 5 7 min,max = (4,8)\n",
        "# vector size = 25 50 75 100 window = 3 min,max = (4,8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrwjUHNp5LHD"
      },
      "source": [
        "# min_n, max_n = (2,4)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oN7wkxjFmj_M",
        "outputId": "0f7fc53f-b454-4412-df97-3118d06df50a"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n =2,\n",
        "                        max_n = 4,\n",
        "                        window = 3,\n",
        "                        vector_size=150,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1666864.52it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1297644.07it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1747390.43it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1630058.02it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1464303.89it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1685828.47it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7378329297820824\n",
            "precision: 0.7372188176313277\n",
            "recall: 0.735613726019861\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.70      0.71      7761\n",
            "           1       0.74      0.77      0.76      8759\n",
            "\n",
            "    accuracy                           0.74     16520\n",
            "   macro avg       0.74      0.74      0.74     16520\n",
            "weighted avg       0.74      0.74      0.74     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.7204600484261501\n",
            "precision: 0.7200538661792832\n",
            "recall: 0.7175642734267\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.67      0.69      7761\n",
            "           1       0.72      0.77      0.74      8759\n",
            "\n",
            "    accuracy                           0.72     16520\n",
            "   macro avg       0.72      0.72      0.72     16520\n",
            "weighted avg       0.72      0.72      0.72     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDicdHe05dwZ"
      },
      "source": [
        "# min_n, max_n = (3,6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzZ2FvS65o8R",
        "outputId": "647d3e1d-19e1-4d9f-c919-4943d80174c7"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n =3,\n",
        "                        max_n = 6,\n",
        "                        window = 3,\n",
        "                        vector_size=150,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1897340.65it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1689569.33it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1661484.52it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1722173.95it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1797126.82it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1654565.14it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7403147699757869\n",
            "precision: 0.739612000793217\n",
            "recall: 0.7383065220276164\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.71      0.72      7761\n",
            "           1       0.75      0.77      0.76      8759\n",
            "\n",
            "    accuracy                           0.74     16520\n",
            "   macro avg       0.74      0.74      0.74     16520\n",
            "weighted avg       0.74      0.74      0.74     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.7254842615012107\n",
            "precision: 0.7249347932906489\n",
            "recall: 0.7228968414015122\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.68      0.70      7761\n",
            "           1       0.73      0.77      0.75      8759\n",
            "\n",
            "    accuracy                           0.73     16520\n",
            "   macro avg       0.72      0.72      0.72     16520\n",
            "weighted avg       0.73      0.73      0.72     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WHkYXcKz5jlO"
      },
      "source": [
        "# min_n, max_n = (4,8)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhbOfXN25tFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b05dd63-e6a0-4c92-8cc1-04aa831aacf7"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n =4,\n",
        "                        max_n = 8,\n",
        "                        window = 3,\n",
        "                        vector_size=150,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1786110.42it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1871339.72it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1724351.19it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1828330.06it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1730561.58it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1824036.74it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7423728813559322\n",
            "precision: 0.7418087792501176\n",
            "recall: 0.740166636855814\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.70      0.72      7761\n",
            "           1       0.75      0.78      0.76      8759\n",
            "\n",
            "    accuracy                           0.74     16520\n",
            "   macro avg       0.74      0.74      0.74     16520\n",
            "weighted avg       0.74      0.74      0.74     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.7265133171912833\n",
            "precision: 0.7261210980559092\n",
            "recall: 0.7237351419966747\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.68      0.70      7761\n",
            "           1       0.73      0.77      0.75      8759\n",
            "\n",
            "    accuracy                           0.73     16520\n",
            "   macro avg       0.73      0.72      0.72     16520\n",
            "weighted avg       0.73      0.73      0.73     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl9XXqTq61Uq"
      },
      "source": [
        "# window 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaiCamEx63ns",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aec4dd1-e652-4568-8ef9-7b722f3be640"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n =4,\n",
        "                        max_n = 18,\n",
        "                        window = 3,\n",
        "                        vector_size=150,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1552322.48it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1759870.78it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1813049.49it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1728351.39it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1778728.25it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1692507.84it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7413438256658595\n",
            "precision: 0.7406840341832425\n",
            "recall: 0.7392769524420473\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.71      0.72      7761\n",
            "           1       0.75      0.77      0.76      8759\n",
            "\n",
            "    accuracy                           0.74     16520\n",
            "   macro avg       0.74      0.74      0.74     16520\n",
            "weighted avg       0.74      0.74      0.74     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.7270581113801453\n",
            "precision: 0.7266140032720497\n",
            "recall: 0.7243590074576265\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.68      0.70      7761\n",
            "           1       0.73      0.77      0.75      8759\n",
            "\n",
            "    accuracy                           0.73     16520\n",
            "   macro avg       0.73      0.72      0.72     16520\n",
            "weighted avg       0.73      0.73      0.73     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jp75B4Ht68ir"
      },
      "source": [
        "# window 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPP_8Vmi67yi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15b2e269-6829-4eb4-86fc-2733a3b8d7ea"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n = 4,\n",
        "                        max_n = 8,\n",
        "                        window = 5,\n",
        "                        vector_size=150,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1783214.46it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1758075.69it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1657319.62it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1880930.81it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1644543.23it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1818187.71it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7454600484261501\n",
            "precision: 0.7447492378612544\n",
            "recall: 0.7435770851941211\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.71      0.72      7761\n",
            "           1       0.75      0.77      0.76      8759\n",
            "\n",
            "    accuracy                           0.75     16520\n",
            "   macro avg       0.74      0.74      0.74     16520\n",
            "weighted avg       0.75      0.75      0.75     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.7285714285714285\n",
            "precision: 0.7284539730274076\n",
            "recall: 0.725521851369723\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.68      0.70      7761\n",
            "           1       0.73      0.78      0.75      8759\n",
            "\n",
            "    accuracy                           0.73     16520\n",
            "   macro avg       0.73      0.73      0.73     16520\n",
            "weighted avg       0.73      0.73      0.73     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvucx8jR7DK5"
      },
      "source": [
        "# window 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMTY4J0G7CcT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a7cc10d-4290-497a-c660-38a5125189e5"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n = 4,\n",
        "                        max_n = 8,\n",
        "                        window = 7,\n",
        "                        vector_size=150,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1671561.36it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1758807.57it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1660481.13it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1668020.19it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1705463.93it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1902634.05it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7430387409200968\n",
            "precision: 0.7423179478227632\n",
            "recall: 0.7411248869662642\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.71      0.72      7761\n",
            "           1       0.75      0.77      0.76      8759\n",
            "\n",
            "    accuracy                           0.74     16520\n",
            "   macro avg       0.74      0.74      0.74     16520\n",
            "weighted avg       0.74      0.74      0.74     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.724818401937046\n",
            "precision: 0.7246048505613947\n",
            "recall: 0.7217917803807636\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.67      0.70      7761\n",
            "           1       0.73      0.77      0.75      8759\n",
            "\n",
            "    accuracy                           0.72     16520\n",
            "   macro avg       0.72      0.72      0.72     16520\n",
            "weighted avg       0.72      0.72      0.72     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR_S6Ntf7LA2"
      },
      "source": [
        "# vector size 25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u15zqRE7J3q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84bea16c-c06b-4cfd-91c0-0b9437f88394"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n = 4,\n",
        "                        max_n = 8,\n",
        "                        window = 3,\n",
        "                        vector_size=25,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1680113.68it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1763157.84it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1917737.08it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1858360.41it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1756382.21it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1715496.67it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7226392251815981\n",
            "precision: 0.72167977048448\n",
            "recall: 0.7208525141861191\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.69      0.70      7761\n",
            "           1       0.73      0.75      0.74      8759\n",
            "\n",
            "    accuracy                           0.72     16520\n",
            "   macro avg       0.72      0.72      0.72     16520\n",
            "weighted avg       0.72      0.72      0.72     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.7220338983050848\n",
            "precision: 0.7214620956985356\n",
            "recall: 0.7194008073040752\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.68      0.70      7761\n",
            "           1       0.73      0.76      0.74      8759\n",
            "\n",
            "    accuracy                           0.72     16520\n",
            "   macro avg       0.72      0.72      0.72     16520\n",
            "weighted avg       0.72      0.72      0.72     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXfr9MHK7SHy"
      },
      "source": [
        "# vector size 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lV6Y95WM7R57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6156687-6fd1-4892-e510-642dff57eccc"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n = 4,\n",
        "                        max_n = 8,\n",
        "                        window = 5,\n",
        "                        vector_size=50,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1624988.84it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1784307.38it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1796567.64it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1840148.73it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1752614.81it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1747073.20it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7402542372881356\n",
            "precision: 0.7395681840561432\n",
            "recall: 0.7382127351580164\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.70      0.72      7761\n",
            "           1       0.75      0.77      0.76      8759\n",
            "\n",
            "    accuracy                           0.74     16520\n",
            "   macro avg       0.74      0.74      0.74     16520\n",
            "weighted avg       0.74      0.74      0.74     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.7348062953995157\n",
            "precision: 0.7344568036089109\n",
            "recall: 0.7321502536408554\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.69      0.71      7761\n",
            "           1       0.74      0.78      0.76      8759\n",
            "\n",
            "    accuracy                           0.73     16520\n",
            "   macro avg       0.73      0.73      0.73     16520\n",
            "weighted avg       0.73      0.73      0.73     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtQWP4xH7aB3"
      },
      "source": [
        "# vector size 75"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ok3oIPl97Z0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76ec0cd-11e7-4dcb-83d8-86fd27b2edb5"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n = 4,\n",
        "                        max_n = 8,\n",
        "                        window = 5,\n",
        "                        vector_size=75,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1538979.09it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1766466.22it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1772957.03it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1625156.55it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1883671.65it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1712088.57it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7409806295399516\n",
            "precision: 0.7403053368390572\n",
            "recall: 0.7389344475898951\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.71      0.72      7761\n",
            "           1       0.75      0.77      0.76      8759\n",
            "\n",
            "    accuracy                           0.74     16520\n",
            "   macro avg       0.74      0.74      0.74     16520\n",
            "weighted avg       0.74      0.74      0.74     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.7317191283292979\n",
            "precision: 0.7314514697611092\n",
            "recall: 0.7289012973038764\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.68      0.70      7761\n",
            "           1       0.73      0.78      0.75      8759\n",
            "\n",
            "    accuracy                           0.73     16520\n",
            "   macro avg       0.73      0.73      0.73     16520\n",
            "weighted avg       0.73      0.73      0.73     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8n3QnWx7d4j"
      },
      "source": [
        "# vector size 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-kf91r67Q0Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82347feb-189e-4f1c-93c3-f29998936797"
      },
      "source": [
        "model = train_fasText(corpus=corpus, \n",
        "                        n_epoch=5, \n",
        "                        name_corpus=\"tweet\", \n",
        "                        sg=1, \n",
        "                        negative=5,\n",
        "                        alpha = 0.065,\n",
        "                        min_n = 4,\n",
        "                        max_n = 8,\n",
        "                        window = 5,\n",
        "                        vector_size=100,\n",
        "                        min_count=2)\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 82598/82598 [00:00<00:00, 1828011.70it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1709638.38it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1766646.38it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1667795.35it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1865806.70it/s]\n",
            "100%|██████████| 82598/82598 [00:00<00:00, 1845147.06it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/scipy/optimize/linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
            "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/optimize.py:204: UserWarning: Line Search failed\n",
            "  warnings.warn('Line Search failed')\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.7378329297820824\n",
            "precision: 0.737116661668664\n",
            "recall: 0.735797239657734\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.70      0.72      7761\n",
            "           1       0.74      0.77      0.76      8759\n",
            "\n",
            "    accuracy                           0.74     16520\n",
            "   macro avg       0.74      0.74      0.74     16520\n",
            "weighted avg       0.74      0.74      0.74     16520\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.7268765133171913\n",
            "precision: 0.7266567807702472\n",
            "recall: 0.7239014737564686\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.67      0.70      7761\n",
            "           1       0.73      0.77      0.75      8759\n",
            "\n",
            "    accuracy                           0.73     16520\n",
            "   macro avg       0.73      0.72      0.72     16520\n",
            "weighted avg       0.73      0.73      0.73     16520\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2h8CY1H7jQX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}