{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tweets_doc2vec_benchmark.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YxwpjDU0-DP",
        "outputId": "12e2400e-849e-403d-e544-5899608734e0"
      },
      "source": [
        "# import libraries\n",
        "from gensim.models import Doc2Vec\n",
        "import gensim\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from sklearn import utils\n",
        "import pandas as pd\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import numpy as np\n",
        "import xgboost \n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "tqdm.pandas(desc=\"progress-bar\")\n",
        "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
        "from sklearn import decomposition, ensemble\n",
        "from collections import Counter\n",
        "from nltk import ngrams"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tqdm/std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
            "  from pandas import Panel\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72Lu7aGp4A19"
      },
      "source": [
        "def classification_report(x_train, x_test, y_train, y_test):\n",
        "  models = []\n",
        "  models.append(('LogisticRegression', linear_model.LogisticRegression(solver='newton-cg',multi_class='multinomial')))\n",
        "  models.append(('RandomForest', ensemble.RandomForestClassifier(n_estimators=100)))\n",
        "\n",
        "  for name, model in models:\n",
        "      clf=model\n",
        "      clf.fit(x_train, y_train)\n",
        "      y_pred=clf.predict(x_test)\n",
        "      print(f\"{name}:\")\n",
        "      print(f\"accuracy: {metrics.accuracy_score(y_pred=y_pred, y_true=y_test)}\")\n",
        "      print(f\"precision: {metrics.precision_score(y_pred=y_pred, y_true=y_test, average='macro')}\")\n",
        "      print(f\"recall: {metrics.recall_score(y_pred=y_pred, y_true=y_test, average='macro')}\")\n",
        "      print(f\"{metrics.classification_report(y_pred=y_pred, y_true=y_test)}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXg0RuZAZlwf"
      },
      "source": [
        "def get_word_counts(data):\n",
        "  words = data.tweet.to_string().split()\n",
        "  return Counter(words)\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g-O9ZWt4ILoE"
      },
      "source": [
        "# word2vec hyper parameters\n",
        "# min_count = corpusta kelimenin en az bulunma sayısı eğer kelime bu kadardan az geçiyorsa anlam ifade etmediği varsayılır(default=5)\n",
        "# vector_size = kelimelerin ifade edileceği vektörün boyut sayısı\n",
        "# window = current ve predicted word arasındaki maksimum mesafe\n",
        "# sg = 0 cbow, 1 skip-gram\n",
        "# negative = eğer sıfırdan büyük olursa negative sampling kullanılır 5-20 arasında olmalı\n",
        "# alpha = başlangıç learning rate\n",
        "# min_alpha = eğitim aşamasında learning rate linear olarak bunu düşer\n",
        "# epoch = iterasyon sayısı\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCziQoyb0qbe"
      },
      "source": [
        "def labelize_tweets_ug(tweets,label):\n",
        "    result = []\n",
        "    prefix = label\n",
        "    for i, t in zip(tweets.index, tweets):\n",
        "        result.append(TaggedDocument(t.split(), [prefix + '_%s' % i]))\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NPao5rpSYA_2"
      },
      "source": [
        "def train_doc2vec(corpus, n_epoch, name_corpus, vector_size, negative, window, min_count, alpha, min_alpha):\n",
        "  cores = multiprocessing.cpu_count()\n",
        "  model = Doc2Vec(size=vector_size, negative=negative, window=window, min_count=min_count, workers=cores, alpha=alpha, min_alpha=min_alpha)\n",
        "  model.build_vocab(corpus)\n",
        "\n",
        "  for epoch in range(n_epoch):\n",
        "    model.train(utils.shuffle(corpus), total_examples=len(corpus), epochs=1)\n",
        "    model.alpha -= 0.002\n",
        "    model.min_alpha = model.alpha\n",
        "\n",
        "  model.save(f\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/trained_embeddings/Doc2Vec_{name_corpus}_size_{vector_size}_window_{window}_min_count_{min_count}.model\")\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vL63uMQfkxrK"
      },
      "source": [
        "def get_mean_vector(model, words):\n",
        "    # remove out-of-vocabulary words\n",
        "    words = [word for word in words if word in model.wv]\n",
        "    if len(words) >= 1:\n",
        "        return np.mean(model[words], axis=0)\n",
        "    else:\n",
        "        return np.zeros((1, model.vector_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVMy-vj1lQQm"
      },
      "source": [
        "def get_vectors(model, corpus):\n",
        "  vectors = []\n",
        "  for sentence in corpus:\n",
        "      vec = get_mean_vector(model, sentence)\n",
        "      vectors.append(vec)\n",
        "  return vectors"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULEuRdQeqyzs"
      },
      "source": [
        "def get_max_len_sentence(series):\n",
        "  res = series.str.split().str.len().max()\n",
        "\n",
        "  print(f\"The maximum length in words are : {res}\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nqZ3LW8lur1"
      },
      "source": [
        "**TWEET METINLERI İÇİN WORD2VEC BENCHMARK**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWfrOSNVl3U-"
      },
      "source": [
        "tweet_train = pd.read_csv(\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/preprocess_train.csv\")\n",
        "tweet_test = pd.read_csv(\"/content/drive/MyDrive/hesaplamalı_anlambilim_ödev/preprocess_test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR7vZvjFmJHN"
      },
      "source": [
        "tweet_test.dropna(inplace=True)\n",
        "tweet_test.reset_index(drop=True,inplace=True)\n",
        "\n",
        "tweet_train.dropna(inplace=True)\n",
        "tweet_train.reset_index(drop=True,inplace=True)\n",
        "\n",
        "x_train=tweet_train.tweet\n",
        "y_train=tweet_train.sentiment.map({'olumlu':1,'olumsuz':-1,'notr':0}).values\n",
        "x_test=tweet_test.tweet\n",
        "y_test=tweet_test.sentiment.map({'olumlu':1,'olumsuz':-1,'notr':0}).values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKY4-aLTmMBM"
      },
      "source": [
        "concat = pd.concat([x_train, x_test])\n",
        "corpus = labelize_tweets_ug(concat, 'all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnxp9_tbv5Gq"
      },
      "source": [
        "corpus_train = pd.DataFrame(x_train)['tweet'].apply(lambda x: x.split())\n",
        "corpus_test = pd.DataFrame(x_test)['tweet'].apply(lambda x: x.split())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MOvAfCWonIDg"
      },
      "source": [
        "# min_count = corpusta kelimenin en az bulunma sayısı eğer kelime bu kadardan az geçiyorsa anlam ifade etmediği varsayılır(default=5)\n",
        "# vector_size = kelimelerin ifade edileceği vektörün boyut sayısı\n",
        "# window = current ve predicted word arasındaki maksimum mesafe\n",
        "# sg = 0 cbow, 1 skip-gram\n",
        "# negative = eğer sıfırdan büyük olursa negative sampling kullanılır 5-20 arasında olmalı\n",
        "# alpha = başlangıç learning rate\n",
        "# min_alpha = eğitim aşamasında learning rate linear olarak bunu düşer\n",
        "# epoch = iterasyon sayısı"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VTyWTQ5prG6r",
        "outputId": "759aa91e-bf16-4980-e2ab-d65f85f31784"
      },
      "source": [
        "get_max_len_sentence(pd.DataFrame(concat).tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The maximum length in words are : 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LoeKUIrq3-C"
      },
      "source": [
        "# epoch=25 negative=5 için \n",
        "# alpha 0.5 0.01 0.05 0.1 her biri window = 3, vector_size = 150 kullanılacak \n",
        "# window 3 5 7 her biri alpha = 0.05, vector_size = 150 kullanılacak \n",
        "# vector_size 25 50 150 200 her biri  için window = 3, alpha = 0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oN7wkxjFmj_M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17468591-dba3-4199-d8d2-8997b0c099be"
      },
      "source": [
        "model_1 = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.5,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zs2aoYW2wKhe",
        "outputId": "5735e12f-aa40-4c4f-c94b-d313745277a2"
      },
      "source": [
        "vectors_train = get_vectors(model=model_1,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model_1,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxDKsaIRwxY5",
        "outputId": "2f8738cf-bc10-42f5-eecb-a0424efdfe3f"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.5414733178654292\n",
            "precision: 0.5404085333694485\n",
            "recall: 0.5241725703838229\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.55      0.68      0.61      1373\n",
            "           0       0.52      0.48      0.49      1160\n",
            "           1       0.55      0.42      0.47       915\n",
            "\n",
            "    accuracy                           0.54      3448\n",
            "   macro avg       0.54      0.52      0.53      3448\n",
            "weighted avg       0.54      0.54      0.54      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.5646751740139211\n",
            "precision: 0.5735727991299947\n",
            "recall: 0.5414843183063426\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.55      0.75      0.64      1373\n",
            "           0       0.56      0.47      0.51      1160\n",
            "           1       0.61      0.40      0.48       915\n",
            "\n",
            "    accuracy                           0.56      3448\n",
            "   macro avg       0.57      0.54      0.54      3448\n",
            "weighted avg       0.57      0.56      0.55      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZ8PHNLTtn2R"
      },
      "source": [
        "# alpha(learning rate) = 0.01"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtO0gImktIbn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4500bfe3-fe5a-4e7c-fa36-e39316995f04"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.01,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfHkCqRetfmk",
        "outputId": "41fd42b0-515f-4bd1-bc0f-a97ae30560bf"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I47m7ABgtl-2",
        "outputId": "1dd5e595-d3a5-4540-839f-a8a9fa9d88dc"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.44576566125290024\n",
            "precision: 0.48117458352468234\n",
            "recall: 0.40303354605059494\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.43      0.79      0.56      1373\n",
            "           0       0.45      0.27      0.34      1160\n",
            "           1       0.56      0.14      0.23       915\n",
            "\n",
            "    accuracy                           0.45      3448\n",
            "   macro avg       0.48      0.40      0.38      3448\n",
            "weighted avg       0.47      0.45      0.40      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.4756380510440835\n",
            "precision: 0.4735616294692864\n",
            "recall: 0.4545301551044114\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.49      0.65      0.56      1373\n",
            "           0       0.44      0.39      0.42      1160\n",
            "           1       0.49      0.32      0.39       915\n",
            "\n",
            "    accuracy                           0.48      3448\n",
            "   macro avg       0.47      0.45      0.45      3448\n",
            "weighted avg       0.47      0.48      0.47      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3NDXq-Vtund"
      },
      "source": [
        "# learning rate 0.05"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbd1U86UtxYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26a893d9-8b61-498d-8762-9bb8816a9f18"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mk53FKIjt0B3",
        "outputId": "a0196b19-9647-4e74-efd7-4b1bda0e9574"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRRL4cFQt4Oo",
        "outputId": "aaa2645b-954d-402a-ecfc-6be8f395f036"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6209396751740139\n",
            "precision: 0.6183514683778863\n",
            "recall: 0.6046258479080957\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.76      0.69      1373\n",
            "           0       0.61      0.55      0.58      1160\n",
            "           1       0.61      0.51      0.55       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.60      0.61      3448\n",
            "weighted avg       0.62      0.62      0.62      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6276102088167054\n",
            "precision: 0.6329431530048656\n",
            "recall: 0.6086500978772053\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.78      0.69      1373\n",
            "           0       0.63      0.55      0.59      1160\n",
            "           1       0.65      0.49      0.56       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.61      0.61      3448\n",
            "weighted avg       0.63      0.63      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz0iXMrlt5Fw"
      },
      "source": [
        "# learning rate 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y67dlPnSt8GK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3023908-dd4e-46c4-caf9-19a9aaa2b787"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.1,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zColPCbsuE5k",
        "outputId": "6cd00142-a459-460b-ac70-a821da73bc69"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pV5tAPDnuJm7",
        "outputId": "fedbb305-0072-414c-a235-e44da16e3d4d"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.627030162412993\n",
            "precision: 0.6254648710300793\n",
            "recall: 0.6129973167770785\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.75      0.68      1373\n",
            "           0       0.62      0.56      0.59      1160\n",
            "           1       0.62      0.53      0.57       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.61      0.62      3448\n",
            "weighted avg       0.63      0.63      0.62      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6209396751740139\n",
            "precision: 0.6329067454002998\n",
            "recall: 0.5954830325057722\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.60      0.82      0.69      1373\n",
            "           0       0.64      0.54      0.59      1160\n",
            "           1       0.66      0.43      0.52       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.63      0.60      0.60      3448\n",
            "weighted avg       0.63      0.62      0.61      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bx4bPZ2_uVfy"
      },
      "source": [
        "# window = 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqXWkzvUuUeK",
        "outputId": "8e87b15f-c893-482d-9efb-88cb2bb07649"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPBRjqXzul1G",
        "outputId": "bbce3252-95e0-4c41-b7f0-125d91c97185"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIYqGZ4_uoFm",
        "outputId": "c2d668fe-8607-4ae2-b320-cc19648ff638"
      },
      "source": [
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6194895591647331\n",
            "precision: 0.6183849363197189\n",
            "recall: 0.6027597753346332\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.76      0.69      1373\n",
            "           0       0.61      0.55      0.58      1160\n",
            "           1       0.62      0.50      0.55       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.60      0.61      3448\n",
            "weighted avg       0.62      0.62      0.61      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6252900232018561\n",
            "precision: 0.6287557206956871\n",
            "recall: 0.6047513217688594\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.79      0.69      1373\n",
            "           0       0.63      0.55      0.58      1160\n",
            "           1       0.64      0.48      0.55       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.60      0.61      3448\n",
            "weighted avg       0.63      0.63      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uo8XEx9KupRg"
      },
      "source": [
        "# window size = 5"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_LfAvpEutjk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acfee144-1df2-4255-b81f-84539197a81a"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 5,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ph8qFhMYuvMk",
        "outputId": "2a20b3af-0dad-4cd1-ea8b-6e119b49019e"
      },
      "source": [
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6203596287703016\n",
            "precision: 0.6184036320174436\n",
            "recall: 0.6045127896831098\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.76      0.69      1373\n",
            "           0       0.61      0.55      0.58      1160\n",
            "           1       0.62      0.51      0.56       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.60      0.61      3448\n",
            "weighted avg       0.62      0.62      0.62      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6281902552204176\n",
            "precision: 0.6315091792195869\n",
            "recall: 0.6103954450902496\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.78      0.69      1373\n",
            "           0       0.63      0.55      0.59      1160\n",
            "           1       0.65      0.50      0.57       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.61      0.61      3448\n",
            "weighted avg       0.63      0.63      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q71fQ3vbu2eC"
      },
      "source": [
        "# window size = 7"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40kIrtDbu1R2",
        "outputId": "af4bf674-a003-40a1-8cf5-cbdc282e2ad5"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 7,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6316705336426914\n",
            "precision: 0.6302541836655527\n",
            "recall: 0.6164201003287674\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.64      0.76      0.69      1373\n",
            "           0       0.62      0.56      0.59      1160\n",
            "           1       0.63      0.53      0.57       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.62      0.62      3448\n",
            "weighted avg       0.63      0.63      0.63      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6310904872389791\n",
            "precision: 0.6342579334545545\n",
            "recall: 0.6129936021506041\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.78      0.69      1373\n",
            "           0       0.64      0.56      0.60      1160\n",
            "           1       0.64      0.50      0.56       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.61      0.62      3448\n",
            "weighted avg       0.63      0.63      0.63      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMnCFd1vu-yL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMEjCkh9vC9D"
      },
      "source": [
        "# vector size = 25\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2bHOBPlvF_A",
        "outputId": "2653db3d-9d5e-498f-caad-bf0992ae6712"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=25,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.580046403712297\n",
            "precision: 0.574468053238078\n",
            "recall: 0.5634051765881732\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.60      0.73      0.66      1373\n",
            "           0       0.56      0.49      0.52      1160\n",
            "           1       0.56      0.47      0.51       915\n",
            "\n",
            "    accuracy                           0.58      3448\n",
            "   macro avg       0.57      0.56      0.56      3448\n",
            "weighted avg       0.58      0.58      0.57      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6232598607888631\n",
            "precision: 0.6252548529301244\n",
            "recall: 0.6045589983555458\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.77      0.69      1373\n",
            "           0       0.61      0.56      0.58      1160\n",
            "           1       0.64      0.49      0.55       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.63      0.60      0.61      3448\n",
            "weighted avg       0.62      0.62      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LYFwoQ9vRIM"
      },
      "source": [
        "# vector  size = 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WwCctArMvT7J",
        "outputId": "b2ef09f3-90bf-4217-cc1d-a51ab836c3aa"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=50,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.597737819025522\n",
            "precision: 0.5950555947585601\n",
            "recall: 0.5796655536968699\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.75      0.67      1373\n",
            "           0       0.58      0.52      0.55      1160\n",
            "           1       0.59      0.47      0.52       915\n",
            "\n",
            "    accuracy                           0.60      3448\n",
            "   macro avg       0.60      0.58      0.58      3448\n",
            "weighted avg       0.60      0.60      0.59      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6241299303944315\n",
            "precision: 0.6278673351151985\n",
            "recall: 0.605032072277116\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.78      0.69      1373\n",
            "           0       0.62      0.55      0.59      1160\n",
            "           1       0.64      0.49      0.55       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.63      0.61      0.61      3448\n",
            "weighted avg       0.63      0.62      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0bBqXNivhF6"
      },
      "source": [
        "# vector size = 100"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElhiDOD8vmHo",
        "outputId": "0bddb578-03d1-4a65-be5b-3ba131413be7"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=100,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6142691415313225\n",
            "precision: 0.6109570023197041\n",
            "recall: 0.5969559573848169\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.75      0.68      1373\n",
            "           0       0.60      0.56      0.58      1160\n",
            "           1       0.60      0.49      0.54       915\n",
            "\n",
            "    accuracy                           0.61      3448\n",
            "   macro avg       0.61      0.60      0.60      3448\n",
            "weighted avg       0.61      0.61      0.61      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6235498839907193\n",
            "precision: 0.6282551143730966\n",
            "recall: 0.6034607578304624\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.79      0.69      1373\n",
            "           0       0.63      0.55      0.58      1160\n",
            "           1       0.64      0.48      0.55       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.63      0.60      0.61      3448\n",
            "weighted avg       0.63      0.62      0.62      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6cZrG4FvuGZ"
      },
      "source": [
        "# vector size = 150"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8visbtc0vrp4",
        "outputId": "78941104-d41c-49b2-8d65-3bc968921d93"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=150,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6116589327146171\n",
            "precision: 0.6094622155468646\n",
            "recall: 0.5955526005518966\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.74      0.68      1373\n",
            "           0       0.60      0.55      0.57      1160\n",
            "           1       0.61      0.50      0.55       915\n",
            "\n",
            "    accuracy                           0.61      3448\n",
            "   macro avg       0.61      0.60      0.60      3448\n",
            "weighted avg       0.61      0.61      0.61      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6200696055684455\n",
            "precision: 0.62714306918924\n",
            "recall: 0.6003849784897052\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.79      0.68      1373\n",
            "           0       0.62      0.53      0.57      1160\n",
            "           1       0.65      0.49      0.56       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.63      0.60      0.60      3448\n",
            "weighted avg       0.62      0.62      0.61      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G4hzi59GvzCH"
      },
      "source": [
        "# vector size = 200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SUBZoTqvyWD",
        "outputId": "4b6ed5fd-f880-4d3d-a939-84546a618bfb"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.05,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 3,\n",
        "                         vector_size=200,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.6203596287703016\n",
            "precision: 0.6188806813077927\n",
            "recall: 0.6046385940632858\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.63      0.75      0.68      1373\n",
            "           0       0.61      0.56      0.58      1160\n",
            "           1       0.62      0.51      0.56       915\n",
            "\n",
            "    accuracy                           0.62      3448\n",
            "   macro avg       0.62      0.60      0.61      3448\n",
            "weighted avg       0.62      0.62      0.62      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6354408352668214\n",
            "precision: 0.6393845501177238\n",
            "recall: 0.6157925457510918\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.62      0.80      0.70      1373\n",
            "           0       0.65      0.55      0.60      1160\n",
            "           1       0.64      0.50      0.56       915\n",
            "\n",
            "    accuracy                           0.64      3448\n",
            "   macro avg       0.64      0.62      0.62      3448\n",
            "weighted avg       0.64      0.64      0.63      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWJnoUaRv25y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ajvxKRPqv4Ne"
      },
      "source": [
        "# en iyiler alpha=0.1, window_size=7, vector_size=200"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT7j2KSUv5zU",
        "outputId": "48050902-fc57-46fc-da1f-5f8b402a74a9"
      },
      "source": [
        "model = train_doc2vec(corpus=corpus, \n",
        "                         n_epoch=25, \n",
        "                         name_corpus=\"tweet\", \n",
        "                         negative=5,\n",
        "                         alpha = 0.1,\n",
        "                         min_alpha = 0.065,\n",
        "                         window = 7,\n",
        "                         vector_size=200,\n",
        "                         min_count=2)\n",
        "\n",
        "\n",
        "vectors_train = get_vectors(model=model,\n",
        "                            corpus=corpus_train)\n",
        "vectors_test = get_vectors(model=model,\n",
        "                            corpus=corpus_test)\n",
        "\n",
        "X_train = np.array(vectors_train)\n",
        "X_train = np.vstack(X_train)\n",
        "X_test = np.array(vectors_test)\n",
        "X_test = np.vstack(X_test)\n",
        "\n",
        "classification_report(x_train=X_train,\n",
        "                      x_test=X_test,\n",
        "                      y_train=y_train,\n",
        "                      y_test=y_test)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
            "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression:\n",
            "accuracy: 0.630800464037123\n",
            "precision: 0.6277542011171744\n",
            "recall: 0.6146182240032301\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.64      0.77      0.70      1373\n",
            "           0       0.61      0.56      0.59      1160\n",
            "           1       0.62      0.52      0.57       915\n",
            "\n",
            "    accuracy                           0.63      3448\n",
            "   macro avg       0.63      0.61      0.62      3448\n",
            "weighted avg       0.63      0.63      0.63      3448\n",
            "\n",
            "RandomForest:\n",
            "accuracy: 0.6412412993039444\n",
            "precision: 0.6577827530078119\n",
            "recall: 0.6171117585174395\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "          -1       0.61      0.83      0.70      1373\n",
            "           0       0.67      0.55      0.60      1160\n",
            "           1       0.69      0.47      0.56       915\n",
            "\n",
            "    accuracy                           0.64      3448\n",
            "   macro avg       0.66      0.62      0.62      3448\n",
            "weighted avg       0.65      0.64      0.63      3448\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4BqMTVFxxkx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}