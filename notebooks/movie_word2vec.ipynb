{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.feature_engineering.benchmark_utils import *\n",
    "from src.feature_engineering.word2vec_benchmark import *\n",
    "from src.data_operations.rw_utils import read_from_csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data is read. Len of the data 83183 and columns Index(['comment', 'film_name', 'point', 'sentiment'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>film_name</th>\n",
       "      <th>point</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jean reno denince zaten leon filmi gelir akla ...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eksin falan izlemek istiyorsaniz bunu izlemeyi...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>yapim hakkinda oyle yazabilirim kitap olur yuz...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>finali yeter sting shape heart bazilari filmle...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jean reno adam kusursuz biri oyunculugu muthis...</td>\n",
       "      <td>Sevginin Gücü</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment      film_name  point  \\\n",
       "0  jean reno denince zaten leon filmi gelir akla ...  Sevginin Gücü    5.0   \n",
       "1  eksin falan izlemek istiyorsaniz bunu izlemeyi...  Sevginin Gücü    5.0   \n",
       "2  yapim hakkinda oyle yazabilirim kitap olur yuz...  Sevginin Gücü    5.0   \n",
       "3  finali yeter sting shape heart bazilari filmle...  Sevginin Gücü    5.0   \n",
       "4  jean reno adam kusursuz biri oyunculugu muthis...  Sevginin Gücü    5.0   \n",
       "\n",
       "   sentiment  \n",
       "0          1  \n",
       "1          1  \n",
       "2          1  \n",
       "3          1  \n",
       "4          1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data from source\n",
    "data = read_from_csv(\"preprocess_movie_sentiment.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.reset_index(drop=True,inplace=True)\n",
    "\n",
    "x=data.comment\n",
    "y=data.sentiment.values\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = labelize_tweets_ug(x, 'all')\n",
    "corpus_train = pd.DataFrame(x_train)['comment'].apply(lambda x: x.split())\n",
    "corpus_test = pd.DataFrame(x_test)['comment'].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The maximum length in words are : 3619\n"
     ]
    }
   ],
   "source": [
    "get_max_len_sentence(pd.DataFrame(data).comment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82598/82598 [00:00<00:00, 1532071.15it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1404574.55it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1799236.15it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1562629.10it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1777888.45it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1560777.60it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 498910.74it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1166480.21it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1452954.94it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1840402.90it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1562643.20it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1880359.10it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1655094.74it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1798759.72it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1688753.97it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1723776.34it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1800423.66it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1654865.47it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 977890.34it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1134518.55it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1089697.92it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1150264.03it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1061784.35it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1149672.37it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 988425.39it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 799288.30it/s]\n"
     ]
    }
   ],
   "source": [
    "model = train_word2vec(corpus=corpus, \n",
    "                         n_epoch=25, \n",
    "                         name_corpus=\"movie\", \n",
    "                         sg=0, \n",
    "                         negative=5,\n",
    "                         alpha = 0.05,\n",
    "                         min_alpha = 0.065,\n",
    "                         window = 3,\n",
    "                         vector_size=300,\n",
    "                         min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.7420096852300242\n",
      "precision: 0.741346098804929\n",
      "recall: 0.7399636023684455\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.71      0.72      7761\n",
      "           1       0.75      0.77      0.76      8759\n",
      "\n",
      "    accuracy                           0.74     16520\n",
      "   macro avg       0.74      0.74      0.74     16520\n",
      "weighted avg       0.74      0.74      0.74     16520\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.713135593220339\n",
      "precision: 0.712775240498976\n",
      "recall: 0.7100111242363203\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.66      0.68      7761\n",
      "           1       0.72      0.76      0.74      8759\n",
      "\n",
      "    accuracy                           0.71     16520\n",
      "   macro avg       0.71      0.71      0.71     16520\n",
      "weighted avg       0.71      0.71      0.71     16520\n",
      "\n",
      "SVM:\n",
      "accuracy: 0.7498789346246973\n",
      "precision: 0.7502729246444519\n",
      "recall: 0.7467752755540019\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.70      0.72      7761\n",
      "           1       0.75      0.80      0.77      8759\n",
      "\n",
      "    accuracy                           0.75     16520\n",
      "   macro avg       0.75      0.75      0.75     16520\n",
      "weighted avg       0.75      0.75      0.75     16520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82598/82598 [00:00<00:00, 185678.37it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1562643.20it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1061257.43it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1217304.19it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 871782.47it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1217184.44it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1166448.79it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1022462.95it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1200315.71it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1103885.19it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 804061.42it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1217937.56it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1235154.67it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1254803.19it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 920208.78it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 845118.51it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1075540.02it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1134522.26it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1134511.12it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1358416.84it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1334966.35it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1235194.30it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1010026.54it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 618042.27it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1089735.63it/s]\n",
      "100%|██████████| 82598/82598 [00:00<00:00, 1380183.03it/s]\n"
     ]
    }
   ],
   "source": [
    "model = train_word2vec(corpus=corpus, \n",
    "                         n_epoch=25, \n",
    "                         name_corpus=\"movie\", \n",
    "                         sg=1, \n",
    "                         negative=5,\n",
    "                         alpha = 0.05,\n",
    "                         min_alpha = 0.065,\n",
    "                         window = 3,\n",
    "                         vector_size=300,\n",
    "                         min_count=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors_train = get_vectors(model=model,\n",
    "                            corpus=corpus_train)\n",
    "vectors_test = get_vectors(model=model,\n",
    "                            corpus=corpus_test)\n",
    "\n",
    "X_train = np.array(vectors_train)\n",
    "X_train = np.vstack(X_train)\n",
    "X_test = np.array(vectors_test)\n",
    "X_test = np.vstack(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression:\n",
      "accuracy: 0.7469128329297821\n",
      "precision: 0.7463283654952496\n",
      "recall: 0.7448296558744907\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.71      0.73      7761\n",
      "           1       0.75      0.78      0.77      8759\n",
      "\n",
      "    accuracy                           0.75     16520\n",
      "   macro avg       0.75      0.74      0.75     16520\n",
      "weighted avg       0.75      0.75      0.75     16520\n",
      "\n",
      "RandomForest:\n",
      "accuracy: 0.7220944309927361\n",
      "precision: 0.7219255562680469\n",
      "recall: 0.7189587343510859\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.67      0.69      7761\n",
      "           1       0.72      0.77      0.75      8759\n",
      "\n",
      "    accuracy                           0.72     16520\n",
      "   macro avg       0.72      0.72      0.72     16520\n",
      "weighted avg       0.72      0.72      0.72     16520\n",
      "\n",
      "SVM:\n",
      "accuracy: 0.7551452784503632\n",
      "precision: 0.7557133298510774\n",
      "recall: 0.7519985150032291\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.70      0.73      7761\n",
      "           1       0.75      0.80      0.78      8759\n",
      "\n",
      "    accuracy                           0.76     16520\n",
      "   macro avg       0.76      0.75      0.75     16520\n",
      "weighted avg       0.76      0.76      0.75     16520\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classification_report(x_train=X_train,\n",
    "                      x_test=X_test,\n",
    "                      y_train=y_train,\n",
    "                      y_test=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
